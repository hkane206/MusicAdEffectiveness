{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Each function is one of the classifiers (trained using sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(data, effectiveness_index):\n",
    "\n",
    "    data = clean_dataset(data)\n",
    "    y = data[effectiveness_index]\n",
    "    y = [int(x) for x in y]\n",
    "    data.drop(effectiveness_index, inplace = True, axis = 1)\n",
    "    X = data\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(X_test, y_test, y_pred):\n",
    "    \n",
    "    #importing confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion)\n",
    "\n",
    "    #importing accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "    print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logistic_regression(path_name, effectiveness_index):\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_model(path_name, effectiveness_index)\n",
    "    \n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(X_train, y_train)\n",
    "    y_pred = logisticRegr.predict(X_test)\n",
    "#     print(\"Accuracy Score: \" + logisticRegr.score(X_test, y_test))\n",
    "    \n",
    "    analyze_model(X_test, y_test, y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_bayes(path_name, effectiveness_index):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_model(path_name, effectiveness_index)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    \n",
    "    analyze_model(X_test, y_test, y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def support_vector(path_name, effectiveness_index):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_model(path_name, effectiveness_index)\n",
    "    \n",
    "    clf = svm.SVC(decision_function_shape='ovr', C=15)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    analyze_model(X_test, y_test, y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(path_name, effectiveness_index):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_model(path_name, effectiveness_index)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    analyze_model(X_test, y_test, y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybridization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybridize(*models):\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        sum += model\n",
    "    \n",
    "    y_pred = []\n",
    "    \n",
    "    for pred in sum:\n",
    "        \n",
    "        y_pred.append(int(sum > 2))\n",
    "        \n",
    "    analyze_model(X_test, y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Videos</th>\n",
       "      <th>Shot_Boundary</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Average_Intensities</th>\n",
       "      <th>Average_Intensities_30</th>\n",
       "      <th>Average_Intensities_60</th>\n",
       "      <th>Optical_Flow</th>\n",
       "      <th>Funny</th>\n",
       "      <th>Average_Memorability</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Exciting</th>\n",
       "      <th>Sentiments</th>\n",
       "      <th>Entropy.1</th>\n",
       "      <th>Optical_Flow.1</th>\n",
       "      <th>Exciting.1</th>\n",
       "      <th>Funny.1</th>\n",
       "      <th>Average_Memorability.1</th>\n",
       "      <th>Language</th>\n",
       "      <th>Topics.1</th>\n",
       "      <th>Sentiments.1</th>\n",
       "      <th>BPM</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>Major/Minor</th>\n",
       "      <th>Sharp/Flat</th>\n",
       "      <th>Effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__C7sd_UDU0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.968461</td>\n",
       "      <td>0.358354</td>\n",
       "      <td>0.417023</td>\n",
       "      <td>0.474382</td>\n",
       "      <td>8.044019e+05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.725416</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.968461</td>\n",
       "      <td>8.044019e+05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.725416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_3sLwG1ZSBA</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.398459</td>\n",
       "      <td>0.267378</td>\n",
       "      <td>0.357319</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>1.787684e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724435</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.398459</td>\n",
       "      <td>1.787684e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_6MAkLJ79LE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.981152</td>\n",
       "      <td>0.298359</td>\n",
       "      <td>0.271681</td>\n",
       "      <td>0.305467</td>\n",
       "      <td>1.278895e+06</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.724163</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.981152</td>\n",
       "      <td>1.278895e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.724163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_6rj5jisB7g</td>\n",
       "      <td>47.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.754034</td>\n",
       "      <td>0.436912</td>\n",
       "      <td>0.503742</td>\n",
       "      <td>0.498872</td>\n",
       "      <td>1.591243e+06</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.725703</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.754034</td>\n",
       "      <td>1.591243e+06</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.725703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_8enIDEKrzA</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.898059</td>\n",
       "      <td>0.412479</td>\n",
       "      <td>0.387862</td>\n",
       "      <td>0.387570</td>\n",
       "      <td>6.150416e+05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.725296</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.898059</td>\n",
       "      <td>6.150416e+05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.725296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Videos  Shot_Boundary  Duration   Entropy  Average_Intensities  \\\n",
       "0  __C7sd_UDU0           19.0      48.0  0.968461             0.358354   \n",
       "1  _3sLwG1ZSBA           35.0      38.0  0.398459             0.267378   \n",
       "2  _6MAkLJ79LE           13.0      31.0  0.981152             0.298359   \n",
       "3  _6rj5jisB7g           47.0      60.0  0.754034             0.436912   \n",
       "4  _8enIDEKrzA           11.0      35.0  0.898059             0.412479   \n",
       "\n",
       "   Average_Intensities_30  Average_Intensities_60  Optical_Flow  Funny  \\\n",
       "0                0.417023                0.474382  8.044019e+05    0.4   \n",
       "1                0.357319                0.327957  1.787684e+06    1.0   \n",
       "2                0.271681                0.305467  1.278895e+06    0.4   \n",
       "3                0.503742                0.498872  1.591243e+06    0.6   \n",
       "4                0.387862                0.387570  6.150416e+05    0.8   \n",
       "\n",
       "   Average_Memorability  Topics  Exciting  Sentiments  Entropy.1  \\\n",
       "0              0.725416    36.0       0.4        11.0   0.968461   \n",
       "1              0.724435    27.0       1.0         6.0   0.398459   \n",
       "2              0.724163    21.0       0.0        30.0   0.981152   \n",
       "3              0.725703     9.0       0.8         5.0   0.754034   \n",
       "4              0.725296    28.0       0.4         6.0   0.898059   \n",
       "\n",
       "   Optical_Flow.1  Exciting.1  Funny.1  Average_Memorability.1  Language  \\\n",
       "0    8.044019e+05         0.4      0.4                0.725416       1.0   \n",
       "1    1.787684e+06         1.0      1.0                0.724435       1.0   \n",
       "2    1.278895e+06         0.0      0.4                0.724163       1.0   \n",
       "3    1.591243e+06         0.8      0.6                0.725703       1.0   \n",
       "4    6.150416e+05         0.4      0.8                0.725296       1.0   \n",
       "\n",
       "   Topics.1  Sentiments.1    BPM    A    B    C    D    E    F    G  \\\n",
       "0      36.0          11.0   93.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1      27.0           6.0  136.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      21.0          30.0   99.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3       9.0           5.0  137.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4      28.0           6.0   91.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "   Major/Minor  Sharp/Flat  Effectiveness  \n",
       "0          0.0         0.0            4.0  \n",
       "1          1.0         0.0            2.0  \n",
       "2          0.0         1.0            3.0  \n",
       "3          1.0         1.0            3.0  \n",
       "4          0.0         0.0            3.0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uploading data\n",
    "data = pd.read_csv(\"/Users/harrisonkane/Downloads/annotations_videos/final data version 3.csv\")\n",
    "data.drop(labels = [i for i in range(1835, len(data))], inplace = True, axis = 0)\n",
    "data.drop(labels = [\"Average_Hue.1\", \"Median_Hue.1\"], inplace = True, axis = 1)\n",
    "data.drop(\"Videos\", inplace = False, axis = 1)\n",
    "new_data = data.drop(labels = [\"Median_Hue\", \"Average_Hue\"], inplace = False, axis = 1)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0   0   0  18]\n",
      " [  0   0   0   0  31]\n",
      " [  0   0   0   0 102]\n",
      " [  0   0   0   0  37]\n",
      " [  0   0   0   0 178]]\n",
      "\n",
      "Accuracy: 0.49\n",
      "\n",
      "Micro Precision: 0.49\n",
      "Micro Recall: 0.49\n",
      "Micro F1-score: 0.49\n",
      "\n",
      "Macro Precision: 0.10\n",
      "Macro Recall: 0.20\n",
      "Macro F1-score: 0.13\n",
      "\n",
      "Weighted Precision: 0.24\n",
      "Weighted Recall: 0.49\n",
      "Weighted F1-score: 0.32\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.00      0.00      0.00        18\n",
      "     Class 2       0.00      0.00      0.00        31\n",
      "     Class 3       0.00      0.00      0.00       102\n",
      "     Class 4       0.00      0.00      0.00        37\n",
      "     Class 5       0.49      1.00      0.65       178\n",
      "\n",
      "    accuracy                           0.49       366\n",
      "   macro avg       0.10      0.20      0.13       366\n",
      "weighted avg       0.24      0.49      0.32       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic_regression(new_data, \"Effectiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0   6   0  13]\n",
      " [  0   0   5   0  18]\n",
      " [  0   0  24   0  78]\n",
      " [  0   0   9   0  37]\n",
      " [  0   0  29   0 147]]\n",
      "\n",
      "Accuracy: 0.47\n",
      "\n",
      "Micro Precision: 0.47\n",
      "Micro Recall: 0.47\n",
      "Micro F1-score: 0.47\n",
      "\n",
      "Macro Precision: 0.17\n",
      "Macro Recall: 0.21\n",
      "Macro F1-score: 0.18\n",
      "\n",
      "Weighted Precision: 0.33\n",
      "Weighted Recall: 0.47\n",
      "Weighted F1-score: 0.38\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.00      0.00      0.00        19\n",
      "     Class 2       0.00      0.00      0.00        23\n",
      "     Class 3       0.33      0.24      0.27       102\n",
      "     Class 4       0.00      0.00      0.00        46\n",
      "     Class 5       0.50      0.84      0.63       176\n",
      "\n",
      "    accuracy                           0.47       366\n",
      "   macro avg       0.17      0.21      0.18       366\n",
      "weighted avg       0.33      0.47      0.38       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3,\n",
       "       5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 3, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 3, 5, 5, 3, 3, 3, 5, 5, 3, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5,\n",
       "       5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 3, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5,\n",
       "       5, 3, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 3, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 3, 3, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5,\n",
       "       5, 3, 5, 3, 3, 5, 5, 3, 3, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 3, 3, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "\n",
    "naive_bayes(new_data, \"Effectiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  0   0   0   0  18]\n",
      " [  0   0   0   0  29]\n",
      " [  0   0   0   0  99]\n",
      " [  0   0   0   0  39]\n",
      " [  0   0   0   0 181]]\n",
      "\n",
      "Accuracy: 0.49\n",
      "\n",
      "Micro Precision: 0.49\n",
      "Micro Recall: 0.49\n",
      "Micro F1-score: 0.49\n",
      "\n",
      "Macro Precision: 0.10\n",
      "Macro Recall: 0.20\n",
      "Macro F1-score: 0.13\n",
      "\n",
      "Weighted Precision: 0.24\n",
      "Weighted Recall: 0.49\n",
      "Weighted F1-score: 0.33\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.00      0.00      0.00        18\n",
      "     Class 2       0.00      0.00      0.00        29\n",
      "     Class 3       0.00      0.00      0.00        99\n",
      "     Class 4       0.00      0.00      0.00        39\n",
      "     Class 5       0.49      1.00      0.66       181\n",
      "\n",
      "    accuracy                           0.49       366\n",
      "   macro avg       0.10      0.20      0.13       366\n",
      "weighted avg       0.24      0.49      0.33       366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harrisonkane/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "support_vector(new_data, \"Effectiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 1  4 13  1  5]\n",
      " [ 1  1 12  0  8]\n",
      " [ 1  9 34 11 41]\n",
      " [ 3  4  9 12 15]\n",
      " [18 13 40 14 96]]\n",
      "\n",
      "Accuracy: 0.39\n",
      "\n",
      "Micro Precision: 0.39\n",
      "Micro Recall: 0.39\n",
      "Micro F1-score: 0.39\n",
      "\n",
      "Macro Precision: 0.26\n",
      "Macro Recall: 0.25\n",
      "Macro F1-score: 0.25\n",
      "\n",
      "Weighted Precision: 0.41\n",
      "Weighted Recall: 0.39\n",
      "Weighted F1-score: 0.40\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.04      0.04      0.04        24\n",
      "     Class 2       0.03      0.05      0.04        22\n",
      "     Class 3       0.31      0.35      0.33        96\n",
      "     Class 4       0.32      0.28      0.30        43\n",
      "     Class 5       0.58      0.53      0.55       181\n",
      "\n",
      "    accuracy                           0.39       366\n",
      "   macro avg       0.26      0.25      0.25       366\n",
      "weighted avg       0.41      0.39      0.40       366\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 5, 3, 5, 3, 3, 5, 3, 4, 5, 5, 4, 5, 3, 3, 4, 4, 3, 2, 5, 2, 4,\n",
       "       4, 5, 3, 2, 5, 5, 5, 3, 4, 5, 2, 3, 5, 1, 1, 5, 4, 4, 3, 3, 5, 3,\n",
       "       4, 3, 5, 3, 3, 1, 5, 2, 4, 3, 3, 2, 5, 2, 5, 3, 5, 5, 3, 3, 3, 5,\n",
       "       3, 5, 3, 3, 4, 5, 5, 3, 3, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 4, 4, 5,\n",
       "       4, 3, 2, 4, 1, 5, 3, 5, 3, 5, 3, 3, 5, 5, 5, 4, 5, 4, 5, 3, 3, 5,\n",
       "       2, 3, 5, 5, 5, 1, 5, 3, 5, 1, 5, 5, 3, 5, 5, 4, 5, 2, 5, 4, 1, 5,\n",
       "       5, 5, 1, 5, 5, 3, 3, 3, 2, 1, 5, 5, 5, 3, 3, 2, 3, 3, 3, 4, 5, 1,\n",
       "       5, 5, 5, 2, 3, 4, 5, 5, 5, 3, 3, 1, 5, 1, 5, 4, 3, 3, 5, 5, 3, 5,\n",
       "       2, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 3, 1, 5, 3, 5, 5, 4, 5, 5, 5,\n",
       "       3, 3, 3, 5, 3, 5, 3, 5, 4, 2, 5, 5, 5, 3, 5, 1, 4, 2, 5, 1, 5, 5,\n",
       "       5, 3, 1, 4, 2, 1, 3, 5, 4, 5, 3, 1, 5, 1, 3, 3, 5, 3, 5, 5, 5, 5,\n",
       "       4, 3, 5, 5, 5, 3, 5, 4, 3, 5, 5, 2, 2, 5, 5, 3, 5, 3, 3, 5, 3, 5,\n",
       "       4, 5, 5, 5, 2, 2, 5, 3, 5, 4, 4, 1, 5, 2, 1, 5, 3, 3, 5, 5, 5, 2,\n",
       "       5, 5, 5, 4, 5, 3, 5, 3, 5, 5, 5, 5, 3, 3, 1, 3, 5, 3, 1, 3, 5, 3,\n",
       "       5, 4, 4, 5, 5, 3, 3, 5, 5, 3, 4, 5, 3, 5, 5, 3, 4, 5, 5, 5, 5, 3,\n",
       "       3, 5, 2, 3, 5, 5, 3, 3, 2, 5, 2, 5, 2, 5, 3, 5, 5, 5, 5, 5, 3, 5,\n",
       "       5, 2, 2, 3, 2, 3, 5, 2, 5, 5, 3, 5, 3, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree(new_data, \"Effectiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
